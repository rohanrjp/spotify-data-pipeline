name: Spotify Ingestion Heartbeat

on:
  schedule:
    - cron: '0 * * * *'  # Runs every hour
  workflow_dispatch:      # Allows manual trigger via "Run workflow" button

jobs:
  ingest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Install uv
        run: curl -LsSf https://astral.sh/uv/install.sh | sh

      - name: Set up Python
        run: uv python install

      - name: Install Dependencies
        run: uv sync --project data-pipeline

      - name: Run Ingestion Script
        env:
          SPOTIFY_CLIENT_ID: ${{ secrets.SPOTIFY_CLIENT_ID }}
          SPOTIFY_CLIENT_SECRET: ${{ secrets.SPOTIFY_CLIENT_SECRET }}
          SPOTIFY_REDIRECT_URL: ${{ secrets.SPOTIFY_REDIRECT_URL }}
          SPOTIFY_REFRESH_TOKEN: ${{ secrets.SPOTIFY_REFRESH_TOKEN }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          DBT_PASSWORD: ${{ secrets.DBT_PASSWORD }}
          DBT_HOST: ${{ secrets.DBT_HOST }}
          DBT_USER: ${{ secrets.DBT_USER }}
        run: |
          export PYTHONPATH=$PYTHONPATH:$(pwd)/data-pipeline/ingestion
          uv run --project data-pipeline python data-pipeline/ingestion/main.py

      - name: Run dbt Transforms
        env:
          DBT_HOST: ${{ secrets.DBT_HOST }}
          DBT_USER: ${{ secrets.DBT_USER }}
          DBT_PASSWORD: ${{ secrets.DBT_PASSWORD }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          # 1. Install dbt dependencies (like dbt-utils if you use it)
          uv run --project data-pipeline dbt deps --project-dir data-pipeline
          
          # 2. Run the models (Bronze -> Silver -> Gold)
          uv run --project data-pipeline dbt run --project-dir data-pipeline --target prod
          
          # 3. Optional: Run tests to make sure no duplicates snuck in
          uv run --project data-pipeline dbt test --project-dir data-pipeline --target prod